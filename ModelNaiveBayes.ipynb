{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ModelNaiveBayes.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zjhbw1ycC7Yu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-k_7gfWUDtQT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "from sklearn.pipeline import Pipeline\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "from nltk.tokenize import word_tokenize\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer \n",
        "ps = PorterStemmer()\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "import pickle "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gOhUfQWEIVG0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 1. Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "icbM4m2SNmp7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def ExploratoryDataAnalysis(Inputdataframe):           \n",
        "        ColumnsList = []\n",
        "        NullList = []\n",
        "        NAList = []\n",
        "        CountList = []    \n",
        "        #Inputdataframe.drop('id', axis=1, inplace=True)\n",
        "        for col in Inputdataframe.columns:        \n",
        "            if(col == 'id' or col == 'comment_text'):\n",
        "                continue;\n",
        "            CountList.append(Inputdataframe[Inputdataframe[col] == 1].shape[0])\n",
        "            ColumnsList.append(col)\n",
        "            NullList.append(Inputdataframe[Inputdataframe[col] == 1][\"comment_text\"].isnull().sum())\n",
        "            NAList.append(Inputdataframe[Inputdataframe[col] == 1][\"comment_text\"].isna().sum())\n",
        "        df = pd.DataFrame(list(zip(ColumnsList,NullList,NAList,CountList)), \n",
        "                   columns =['Column Name','Null Count','NA Count','Record Count']) \n",
        "        return df.transpose(),\"Total Records : {}\".format(Inputdataframe.shape[0])        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vu36DXwNsyH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def GetCleanedData(dataset):\n",
        "    stop_words= stopwords.words(\"english\")    \n",
        "    Remove_words = [ 'no', 'nor', 'not','don', \"don't\", 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\",'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n",
        "    for item in Remove_words: \n",
        "        stop_words.remove(item) \n",
        "        \n",
        "    for i in range(dataset.shape[0]):\n",
        "        comment_text = dataset.iloc[i, 1]\n",
        "\n",
        "        # remove non alphabatic characters\n",
        "        comment_text = re.sub('[^A-Za-z]', ' ', comment_text)\n",
        "\n",
        "        # make words lowercase, because Go and go will be considered as two words\n",
        "        comment_text = comment_text.lower()\n",
        "\n",
        "        # tokenising\n",
        "        tokenized_comments = word_tokenize(comment_text)\n",
        "\n",
        "        #Remvoing stop words and Stemming\n",
        "        comment_processed = []\n",
        "        for item in tokenized_comments:\n",
        "            if item not in (stop_words):                           \n",
        "              if(len(item) <= 40):\n",
        "                strstem = ps.stem(item) \n",
        "                comment_processed.append(strstem)\n",
        "        dataset.iloc[i, 1] = \" \".join(comment_processed)  \n",
        "        print(i)\n",
        "    return dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRP1HsGOysjs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def GetDataSample(dataset):\n",
        "  GetCleanedData(dataset)\n",
        "  categories = ['toxic','severe_toxic','obscene','threat','insult','identity_hate']\n",
        "  x_train, x_test, y_train, y_test = train_test_split(dataset[\"comment_text\"], dataset[categories], train_size=0.95, shuffle=True, random_state=1)\n",
        "  return x_train, x_test, y_train, y_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BHcJhqnOCWV6",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i40XhygNN4-n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def NaiveBayesModel(dataset):\n",
        "    x_train, x_test, y_train, y_test = GetDataSample(dataset)\n",
        "    \n",
        "    # ngram_range = 1,2 = bigram model\n",
        "    NB_Classifier = Pipeline([\n",
        "                ('tfidf', TfidfVectorizer(ngram_range=(1,2), max_features = 50000)),\n",
        "                ('clf', OneVsRestClassifier(MultinomialNB(fit_prior=True, class_prior=None))),\n",
        "            ])\n",
        "    \n",
        "    NB_Classifier.fit(x_train, y_train)\n",
        "    prediction = NB_Classifier.predict(x_test) \n",
        "    print('Test accuracy is {}'.format(accuracy_score(y_test, prediction)))\n",
        "      \n",
        "    return NB_Classifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZbnoIZwPbkQ_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = pd.read_csv('/content/gdrive/My Drive/DataScience/ProjectWork/train.csv')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q6sZ_DIXAPEv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "NB_Model  = NaiveBayesModel(dataset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JUJOWUz74UQA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(comment,model):\n",
        "  categories = ['toxic','severe_toxic','obscene','threat','insult','identity_hate']\n",
        "  probs = model.predict_proba([comment])[0]\n",
        "  for (prob, category) in zip(probs, categories): \n",
        "    print('{} : {}%'.format(category, (round(prob,2)*100) ))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "llQHfj8_43lL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predict(\"he is a good boy. he loves to talk shit.\",NB_Model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbp8OTd3elQa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#save the model to a file\n",
        "with open('NB_Model_lat.pkl', 'wb') as f:\n",
        "    pickle.dump(NB_Model, f)\n",
        "file = drive.CreateFile({'title' : 'NB_Model_lat.pkl'})\n",
        "file.SetContentFile('NB_Model_lat.pkl')\n",
        "file.Upload() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gq_4cbl7fNyJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubysgkaO4T8H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KqP6f4lwge9L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GM_GzRvQ3i_w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}